{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This tutorial uses a Jupyter notebook environment with a Python 2 kernel. I suggest downloading and installing Anaconda distribution (https://anaconda.org/anaconda/python) of Python 2 and learning how to launch Jupyter notebooks from the documentation. It is relatively straightforward and should be easy to learn. We use Keras for implementing a basic neural network.\n",
    "\n",
    "**NOTE:** This tutorial assumes you are familiar with basic Python usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We will train a neural network model on the gene expression data from HW5 using Keras (https://keras.io/). The data is already split into train and validation sets and stored in numpy array format on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the data\n",
    "These are numpy arrays saved to disk using np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xtrain = np.load('Xtrain.npy')\n",
    "Ytrain = np.load('Ytrain.npy')\n",
    "Xvalid = np.load('Xvalid.npy')\n",
    "Yvalid = np.load('Yvalid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(Xtrain)\n",
    "print type(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The labels are one-hot-encoded numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20660L, 46L)\n",
      "(729L, 46L)\n"
     ]
    }
   ],
   "source": [
    "print Ytrain.shape\n",
    "print Yvalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nn.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras functionality that we need.\n",
    "* Sequential = Feed forward neural network\n",
    "* Dense = fully connected layer.\n",
    "* Activation = setting activations of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numFeatures = Xtrain.shape[1]\n",
    "numLabels = Ytrain.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(numFeatures,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(numLabels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP**: Play around with these hyperparameters in a systematic way. Tweak learning rate, mini-batch size, activation functions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               2050000   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46L)               4646      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46L)               0         \n",
      "=================================================================\n",
      "Total params: 2,054,646\n",
      "Trainable params: 2,054,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20660 samples, validate on 729 samples\n",
      "Epoch 1/3\n",
      "20660/20660 [==============================] - 12s - loss: 2.1807 - acc: 0.4529 - val_loss: 3.5470 - val_acc: 0.1824\n",
      "Epoch 2/3\n",
      "20660/20660 [==============================] - 10s - loss: 1.5124 - acc: 0.5973 - val_loss: 3.4404 - val_acc: 0.1632\n",
      "Epoch 3/3\n",
      "20660/20660 [==============================] - 11s - loss: 1.2567 - acc: 0.6628 - val_loss: 3.3603 - val_acc: 0.1989\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain,\n",
    "          y=Ytrain,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(Xvalid,Yvalid),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc [0.45285575989947546, 0.59728944818601948, 0.6627783155972129]\n",
      "loss [2.1807313720115964, 1.5124030058750917, 1.2567265266716654]\n",
      "val_acc [0.18244170106242222, 0.16323731135479871, 0.19890260624869208]\n",
      "val_loss [3.5469755658724016, 3.4403964891028176, 3.3602641207691084]\n"
     ]
    }
   ],
   "source": [
    "for val in history.history:\n",
    "    print val, history.history[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIP: Look at your learning curves\n",
    "Plot training and validation loss against epoch number to see how your model is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIP: Always save your model parameters so that you can refer back to them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('mlp_new_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('mlp_old_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/729 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predTrain = model.predict_classes(Xtrain)\n",
    "predValid = model.predict_classes(Xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 45 45 ..., 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "print predTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940900290416\n",
      "0.433470507545\n"
     ]
    }
   ],
   "source": [
    "trainAccuracy = 1.0*np.sum(predTrain==np.argmax(Ytrain,axis=1))/predTrain.size\n",
    "validAccuracy = 1.0*np.sum(predValid==np.argmax(Yvalid,axis=1))/predValid.size\n",
    "print trainAccuracy\n",
    "print validAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.177492739593\n",
      "0.310013717421\n"
     ]
    }
   ],
   "source": [
    "maxClassValidPercentage = np.max(np.sum(Yvalid,axis=0))/np.sum(Yvalid)\n",
    "maxClassTrainPercentage = np.max(np.sum(Ytrain,axis=0))/np.sum(Ytrain)\n",
    "print maxClassTrainPercentage\n",
    "print maxClassValidPercentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Metrics to use:\n",
    "\n",
    "<ul>\n",
    "  <li>0-1 Accuracy</li>\n",
    "  <li>Compare with majority Class Percentage</li>\n",
    "  <li>Plot the learning curve to see if you're overfitting</li>\n",
    "  <li>Area Under Receiver Operating Characteristic (auROC) curve</li>\n",
    "  <li>Area Under Precision Recall Curve (AUPR) - Useful when there are imbalanced classes</li>\n",
    "  <li>F1-Score = PR/(P+R)</li>\n",
    "  <li>Confusion Matrix - visualize which labels are confusing for the model</li>\n",
    "</ul>\n",
    "#### All of these can be found in scikitlearn or other toolboxes or easily implemented by self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips\n",
    "* If you have not started, then start ASAP. There is lot of engineering effort involved even in getting the data into the right formats that can be read in by classifiers.\n",
    "* Use standard format for data (numpy array/MATLAB matrix) so that workflow is optimized\n",
    "* **Data splitting method is important**\n",
    "* Debug your models on a small subset of the data\n",
    "* You could try to pick model architecture by looking at overfitting on a small subset of the data\n",
    "* Train on the full set after that and then do hyperparameter search if needed\n",
    "* Always save your model parameters so that you can go back to them when needed\n",
    "* Learning rate is usually the first hyperparameter that you should try to tune\n",
    "* Document hyperparameter searches in a systematic way (maintain a spreadsheet/table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Libraries and Toolboxes (Also check Piazza)\n",
    "* Alternative neural network toolboxes with GPU support - tensorflow, theano, torch/pytorch\n",
    "* General Machine Learning toolboxes - scikitlearn (Python), shogun (Python, R, Octave) - implementations of most typical classifiers, clustering algorithms including model evaluation metrics\n",
    "* Saving objects, loading/unloading data - numpy.save, numpy.load, pickle, .mat format, pandas.read_table, readr::read_tsv, data.table::fread, saveRDS\n",
    "* Plotting - matplotlib/seaborn (Python), ggplot2 (R, Python), plotly (general)\n",
    "* Command line tools - head, tail, less -S, more, awk, cat"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
