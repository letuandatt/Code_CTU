{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Probabilistic Reasoning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$ \\textbf{Exercise 1: Follow the robot} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you get your hands on a robot that has various sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{a)}$ The robot has a very cheap camera on board, so it's not very accurate at reading colors. After color calibration you know the camera color model. Assume the robot is located in a white room with 5 boxes: 2 red, 2 green and a blue one. The robot moves towards a box and the camera reads green. How likely is it that the box is actually green? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first write down the color mapping as a 2d numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8  0.1  0.1]\n",
      " [ 0.1  0.6  0.2]\n",
      " [ 0.1  0.3  0.7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "color_model = np.array([[0.8, 0.1, 0.1],\n",
    "                         [0.1, 0.6, 0.2],\n",
    "                         [0.1, 0.3, 0.7]])\n",
    "\n",
    "print(color_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also for convenience define some index variables to access the array entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R, G, B = 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantities of the boxes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1]\n"
     ]
    }
   ],
   "source": [
    "quantities = np.array([2, 2, 1])\n",
    "print(quantities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the asked probability, we will use Bayes' rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(x=G|z=G) = p(z=G|x=G) \\frac{p(x=G)}{p(z=G)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute each term. \n",
    "The first term $p(z=G|x=G)$ is the <b>likelihood</b> and is exactly why we need a sensor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "p_readGreenWhileGreen = color_model[G][G]\n",
    "print(p_readGreenWhileGreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second term is the <b>prior</b>. In this case we know the prior exactly: $$p(x=G) = \\frac{n_G}{n_R + n_G + n_B} = \\frac{2}{5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "p_isGreen = quantities[G] / sum(quantities)\n",
    "print(p_isGreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator is the <b>normalizer</b> and we compute it by marginalization: $$p(z=G) = p(z=G|x=R)p(x=R) + p(z=G|x=G)p(x=G) + p(z=G|x=B)p(x=B) = \\sum_{X \\in \\{R,G,B\\}} p(z=G|x=X)p(x=X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last sum is just an inner product. The first vector is given by the row in the color mapping that corresponds to observing the color green. It is the likelihood of each color when reading green. The second vector is just the prior probability of each color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_likelihoods = color_model[G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4  0.4  0.2]\n"
     ]
    }
   ],
   "source": [
    "p_isColor = quantities / sum(quantities)\n",
    "print(p_isColor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the probability of sensing green is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "p_readGreen = np.dot( p_likelihoods, p_isColor)\n",
    "print(p_readGreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need. The probability that the box is actually green is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "p_isGreenWhileReadGreen = p_readGreenWhileGreen * p_isGreen / p_readGreen\n",
    "print(p_isGreenWhileReadGreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{b)}$ The robot has a proximity sensor and it uses it to measure its distance from a door. The sensor can be modeled using a continuous random variable\n",
    "with a Normal distribution with $\\sigma_1 = 0.3$. Express the sensor model $p(z_t|x_t)$ in the\n",
    "full form (not the shorthand notation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(z_t|x_t) = \\cal{N} (z_t ; x_t, \\sigma_1^2)\n",
    "= \\frac{1}{\\sigma_1\\sqrt{2\\pi}} \\exp \\left( - \\frac{(z_t-x_t)^2}{2\\sigma_1^2} \\right) \n",
    "= \\frac{1}{0.3\\sqrt{2\\pi}} \\exp \\left( - \\frac{(z_t-x_t)^2}{2 \\cdot 0.3^2} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{c)}$ Now the robot moves into a hallway. Initially it knows it is located\n",
    "at the door ($x_0=0$). The robot can execute move commands but the result of the\n",
    "action is not always perfect. Assume that the robot moves with constant speed $v$.\n",
    "The motion can also be modeled with a Gaussian with deviation $\\sigma_2 = 0.1$. Write\n",
    "the motion model $p(x_t|x_{t−1}, u_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motion can also be modeled with a Gaussian. We just need to think about what\n",
    "is our mean and what is our variance. The variance is the square of the standard deviation which given as the actuator noise\n",
    "$\\sigma_2 = 0.1$. Our mean is the position we expect the robot to be at, after the motion\n",
    "$u_t$. Since our robot moves with constant speed $v$, the expected position is simply\n",
    "$\\mu = x_{t−1} + v \\Delta t $. Therefore we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(x_t|x_{t-1}, u_t) = \\cal{N} (x_t; x_{t-1} + v \\Delta t, \\sigma_2^2)\n",
    "= \\frac{1}{\\sigma_2 \\sqrt{2\\pi}} \\exp \\left( - \\frac{(x_t - (x_{t-1}+ v \\Delta t))^2}{2\\sigma_2^2} \\right) \n",
    "= \\frac{1}{0.1\\sqrt{2\\pi}} \\exp \\left( - \\frac{(x_t - (x_{t-1}+ v \\Delta t))^2}{2 \\cdot 0.1^2} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{d)}$ You let the robot run with a speed of 1 m/s. The robot only runs\n",
    "forward and it updates its belief every second. Assume you get the following sensor\n",
    "measurements in the first 3 seconds: $\\{z_1 = 1.2, z_2 = 1.6, z_3 = 2.5\\}$.\n",
    "Further assume that the hallway is only 5 meters long. Where\n",
    "does the robot believe it is located with respect to the door after 3 seconds? How\n",
    "certain is it about its location?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model the state variable $x$ as a continuous random variable with values between 0\n",
    "and 5, where 0 means that the robot is at the door. We want to compute the robot’s\n",
    "belief. Initially, the robot knows it is located at the door ($x_0=0$), therefore we have\n",
    "$Bel(x_0 = 0) = +\\infty $. We then use the Bayes Filter algorithm to compute the belief after\n",
    "3 seconds, namely $Bel(x_3)$. Since this is a recursive algorithm we have to compute the\n",
    "belief at each time step. The general equation of the Bayes filter is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Bel(x_t) = \\eta_t \\cdot p(z_t|x_t) \\cdot \\int p(x_t | x_{t-1}, u_t) \\cdot Bel(x_{t-1}) dx_{t-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case the space can be reduced to an interval from 0 to 5, so we get a definite integral. Furthermore, there is only one action $u$ that is taken at every time step, which is to move with constant speed 1 m/s.\n",
    "Let us see how we would compute the belief after one second: |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Bel(x_1) = \\eta_1 \\cdot p(z_1|x_1) \\cdot \\int_0^5 p(x_1 | x_{0}, u) \\cdot Bel(x_{0}) dx_0 $$ \n",
    "\n",
    "which reduces to $$ Bel(x_1) = \\eta_1 \\cdot p(z_1|x_1) \\cdot p(x_1 | x_{0}=0, u)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the sensor model from question 1b and the motion model from question 1c, so we can substitute with the normal distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(z_1|x_1) = \\frac{1}{0.3\\sqrt{2\\pi}} \\exp \\left( - \\frac{(1.2-x_1)^2}{2 \\cdot 0.3^2} \\right) $$\n",
    "              \n",
    "$$ p(x_1 | x_0, u) = \\frac{1}{0.1\\sqrt{2\\pi}} \\exp \\left( - \\frac{(x_1 - (0 + 1 \\cdot 1))^2}{2 \\cdot 0.1^2} \\right) $$\n",
    "\n",
    "$$ \\eta_1 = \\left( \\int_0^5 p(z_1=1.2|x_1) \\cdot p(x_1|x_0=0, u) dx_1 \\right)^{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the sensor model and the action model are both represented by Gaussian pdfs (in 1-D). This is a particular instance of Bayes Filter algorithms, namely the Kalman Filter. The great advantage of the Kalman Filter is that we can do all computations in closed form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral $\\int p(x_t | x_{t-1}, u_t) \\cdot Bel(x_{t-1}) dx_{t-1}$ is a convolution of Gaussian pdfs. It turns out that this results to another Gaussian pdf with extremely easy to compute parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\int \\cal N(x ; \\mu_1, \\sigma_1^2) \\cdot \\cal N(x ; \\mu_2, \\sigma_2^2) dx = \\cal N(x ; \\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this follows that the product of the sensor model with the integral is a product of two Gaussian pdfs which also results in a Gaussian pdf:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cal N(x ; \\mu_1, \\sigma_1^2) \\cdot \\cal N(x ; \\mu_2, \\sigma_2^2) = \\cal N \\left( x ; \\frac{\\sigma_2^2 \\mu_1 + \\sigma_1^2 \\mu_2}{\\sigma_1^2 + \\sigma_2^2}, \\frac{\\sigma_1^2 \\sigma_2^2}{\\sigma_1^2 + \\sigma_2^2} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, every action and measurement update is extremely efficient as we only have to compute the new parameters of the Gaussians. If the models were arbitrary distributions, we would have to compute the updates explicitly.<br> See also the full code examples for both cases written in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\textbf{Exercise 2: An overview of ML methods} $\n",
    "\n",
    "Try to find (for example by internet search or from the book (Bishop)) at least\n",
    "5 examples for learning techniques that have not been discussed in class. Describe these\n",
    "techniques briefly and classify them with respect to the categories presented in the lecture.\n",
    "Here are some examples of learning algorithms:\n",
    "\n",
    "<ol>\n",
    "<li> Mean-shift clustering: Unsupervised learning </li>\n",
    "<li> Perceptron algorithm: Discriminant function</li>\n",
    "<li> Neural Networks: Discriminative model</li>\n",
    "<li> Bayes classifier: Generative model</li>\n",
    "<li> Conditional Random Field: Discriminative model</li>\n",
    "<li> AdaBoost: Discriminant function</li>\n",
    "</ol>\n",
    "\n",
    "For a detailed explanation, please see the textbook Pattern Recognition and Machine\n",
    "Learning by C.M. Bishop or the slides."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}